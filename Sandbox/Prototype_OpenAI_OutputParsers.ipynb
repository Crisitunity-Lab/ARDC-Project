{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM7bVq2+NB13LBEpAn8w/yq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Crisitunity-Lab/ARDC-Project/blob/main/Sandbox/Prototype_OpenAI_OutputParsers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using LangChain with Output Parsers\n",
        "Output parsers are responsible for specifying the schema a language model should respond to a request in. This requires a schema to be specified with the information required.\n",
        "\n",
        "## LLM Used\n",
        "Using OpenAI as the base foundation model."
      ],
      "metadata": {
        "id": "UUmFMPUK3ztL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI8ImO-SzHe8",
        "outputId": "a585ff80-d3ea-4e0b-8460-05180b31ec5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain openai tiktoken cohere"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKuVEhZRzST-",
        "outputId": "0e9e03be-8f63-4eac-c23e-abe595ffe3f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.0.286\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, async-timeout, dataclasses-json, langsmith, numexpr, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert OpenAI API Key\n",
        "api_key = \"<insert key>\""
      ],
      "metadata": {
        "id": "Dp5XWxZqzY1G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Set temp to zero to limit the variability of output from the model\n",
        "chat_llm = ChatOpenAI(temperature=0.0, openai_api_key=api_key)"
      ],
      "metadata": {
        "id": "lAXFTmW3zfgi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a template string that has a place holder for the tweet. The prompt tries to give the model some background on how to \"think\" about the question being posed."
      ],
      "metadata": {
        "id": "xauwitLF4ej5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_string = \"\"\"You are crisis response person that needs to understand the relevance of tweets. \\\n",
        "You help identify relevant information in a crisis.\n",
        "\n",
        "Take the tweet below delimited by triple backticks and use it to understand the sentiment, the crisis type and country it relates to.\n",
        "\n",
        "tweet: ```{tweet}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_VY39He4zgs2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# Create the prompt template that takes the raw blob with instructions\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)"
      ],
      "metadata": {
        "id": "v0Xvtkpv0LJH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What does the prompt look like?\n",
        "prompt_template.messages[0].prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLJZPoXz0OQd",
        "outputId": "c0c756ff-c0d6-454c-a659-8cbab752712d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['tweet'], output_parser=None, partial_variables={}, template='You are crisis response person that needs to understand the relevance of tweets. You help identify relevant information in a crisis.\\n\\nTake the tweet below delimited by triple backticks and use it to understand the sentiment, the crisis type and country it relates to.\\n\\ntweet: ```{tweet}```\\n', template_format='f-string', validate_template=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass in the first message from the 2013 Alberta Floods\n",
        "msg = \"RT @CBCAlerts: Canmore, Alta. declares state of emergency due to flooding  - with some residents being moved to community centre #Alberta\""
      ],
      "metadata": {
        "id": "jCOds5240TnG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add message to prompt template\n",
        "tweet_response = prompt_template.format_messages(tweet=msg)"
      ],
      "metadata": {
        "id": "9PgN396C0fgH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6ua-x9B0pdv",
        "outputId": "b9cfcdee-ab0c-40d2-8ef1-e6be830817c8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='You are crisis response person that needs to understand the relevance of tweets. You help identify relevant information in a crisis.\\n\\nTake the tweet below delimited by triple backticks and use it to understand the sentiment, the crisis type and country it relates to.\\n\\ntweet: ```RT @CBCAlerts: Canmore, Alta. declares state of emergency due to flooding  - with some residents being moved to community centre #Alberta```\\n', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the model on the prompt template\n",
        "consultant_response = chat_llm(tweet_response)"
      ],
      "metadata": {
        "id": "E9UTCAMp0t4K"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print output from the model\n",
        "print(consultant_response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd-qwFC50xX2",
        "outputId": "e5521135-805f-4b6c-85ea-8d109f8c4be1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: The sentiment of the tweet is not explicitly mentioned. However, based on the information provided, it can be inferred that the sentiment is likely negative or concerning due to the declaration of a state of emergency and the need to move residents to a community centre.\n",
            "\n",
            "Crisis Type: The crisis type mentioned in the tweet is flooding. Canmore, Alberta has declared a state of emergency specifically due to flooding.\n",
            "\n",
            "Country: The tweet relates to Canada, specifically the province of Alberta. Canmore is a town located in Alberta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output fron the model doesn't look too bad, although it is a little wordy and may not be useful for our use case.\n",
        "\n",
        "In the next bits we'll use the Structured Output Parser to receive stucture from the model."
      ],
      "metadata": {
        "id": "dr24gctA5KZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser\n",
        "\n",
        "# Set the output Response Schema\n",
        "sentiment_schema = ResponseSchema(name=\"sentiment\",\n",
        "                             description=\"This is the senitment of the tweet\")\n",
        "\n",
        "crisis_type_schema = ResponseSchema(name=\"crisis_type\",\n",
        "                                      description=\"This is type of crisis (e.g. flooding, bushfire, typhoon)\")\n",
        "\n",
        "country_schema = ResponseSchema(name=\"country\",\n",
        "                                    description=\"This is the country where the crisis is located\")\n",
        "\n",
        "response_schemas = [sentiment_schema,\n",
        "                    crisis_type_schema,\n",
        "                    country_schema]"
      ],
      "metadata": {
        "id": "7P6ar2-V08MW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
      ],
      "metadata": {
        "id": "yae96TOa1beH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the format instructions to be passed to the model\n",
        "format_instructions = output_parser.get_format_instructions()"
      ],
      "metadata": {
        "id": "4SifaLxo1eA6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the format instructions\n",
        "print(format_instructions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rdtaz4_1gcF",
        "outputId": "195b3768-6abe-48d0-ad6e-dc2970079232"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"sentiment\": string  // This is the senitment of the tweet\n",
            "\t\"crisis_type\": string  // This is type of crisis (e.g. flooding, bushfire, typhoon)\n",
            "\t\"country\": string  // This is the country where the crisis is located\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now add the format instructions to the template string\n",
        "template_string = \"\"\"You are crisis response person that needs to understand the relevance of tweets. \\\n",
        "You help identify relevant information in a crisis.\n",
        "\n",
        "Take the tweet below delimited by triple backticks and use it to understand the sentiment, the crisis type and country it relates to.\n",
        "\n",
        "tweet: ```{tweet}```\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WOoscbUe1k3m"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create prompt template with the format instructions included\n",
        "prompt = ChatPromptTemplate.from_template(template=template_string)\n",
        "\n",
        "messages = prompt.format_messages(tweet=msg,\n",
        "                                format_instructions=format_instructions)\n",
        "\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XedZVsx1rnQ",
        "outputId": "95a6de9c-d9ca-496e-e5dd-3573bde0ee2a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='You are crisis response person that needs to understand the relevance of tweets. You help identify relevant information in a crisis.\\n\\nTake the tweet below delimited by triple backticks and use it to understand the sentiment, the crisis type and country it relates to.\\n\\ntweet: ```RT @CBCAlerts: Canmore, Alta. declares state of emergency due to flooding  - with some residents being moved to community centre #Alberta```\\n\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"sentiment\": string  // This is the senitment of the tweet\\n\\t\"crisis_type\": string  // This is type of crisis (e.g. flooding, bushfire, typhoon)\\n\\t\"country\": string  // This is the country where the crisis is located\\n}\\n```\\n', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get response from model\n",
        "response = chat_llm(messages)\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUKCPAWj125O",
        "outputId": "b65f5561-1219-4261-cd62-1dc24fd281d8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='```json\\n{\\n\\t\"sentiment\": \"neutral\",\\n\\t\"crisis_type\": \"flooding\",\\n\\t\"country\": \"Canada\"\\n}\\n```', additional_kwargs={}, example=False)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Return response as a dict to allow for easy extraction of formatted data\n",
        "response_as_dict = output_parser.parse(response.content)\n",
        "response_as_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MAHsSVx16ts",
        "outputId": "20c631bc-8ccd-4d42-ef54-42b6545507e6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentiment': 'neutral', 'crisis_type': 'flooding', 'country': 'Canada'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results\n",
        "The output seems to be nicely formatted and returns values that seem to valid and may be useful, but this has happened before only for the next prompt to return something that doesn't match the required output.\n",
        "\n",
        "## Next Steps\n",
        "Try mode tweets from the 2013 Alberta floods, as well as the 2012 Colorado Wildfires"
      ],
      "metadata": {
        "id": "GEclBzKC59Q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Next message from the Alberta Floods\n",
        "msg_2 = \"RT @GlobalCalgary: If you are in #Canmore and need help, an emergency line has been set up. Pls call 403-678-1551. #abstorm #abflood\""
      ],
      "metadata": {
        "id": "3FByE4SJ2Ixs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(template=template_string)\n",
        "\n",
        "messages = prompt.format_messages(tweet=msg_2,\n",
        "                                format_instructions=format_instructions)\n",
        "\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckB9uwGQ2Pbo",
        "outputId": "e4d3d749-2ae7-471e-d1c0-2ebda02d4412"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='You are crisis response person that needs to understand the relevance of tweets. You help identify relevant information in a crisis.\\n\\nTake the tweet below delimited by triple backticks and use it to understand the sentiment, the crisis type and country it relates to.\\n\\ntweet: ```RT @GlobalCalgary: If you are in #Canmore and need help, an emergency line has been set up. Pls call 403-678-1551. #abstorm #abflood```\\n\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"sentiment\": string  // This is the senitment of the tweet\\n\\t\"crisis_type\": string  // This is type of crisis (e.g. flooding, bushfire, typhoon)\\n\\t\"country\": string  // This is the country where the crisis is located\\n}\\n```\\n', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_llm(messages)\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4wrpw5s2WLp",
        "outputId": "e711da3a-f509-4cd0-8e18-7e6d82bbc96a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='```json\\n{\\n\\t\"sentiment\": \"neutral\",\\n\\t\"crisis_type\": \"flooding\",\\n\\t\"country\": \"Canada\"\\n}\\n```', additional_kwargs={}, example=False)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_as_dict = output_parser.parse(response.content)\n",
        "response_as_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYZU5tke2amU",
        "outputId": "b9be681d-3a5c-449b-8710-fceb50c74fc3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentiment': 'neutral', 'crisis_type': 'flooding', 'country': 'Canada'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks useful but is the same output as the first tweet. This may be right - after all it's the same crisis - but want to make sure it's working OK."
      ],
      "metadata": {
        "id": "E2TJEdD-6jaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Another message from the Alberta Floods\n",
        "msg_3 = \"RT @CgyCA: UPDATE: Erlton, Victoria Park, Cliff Bungalow and Inglewood added to #yyc evacuation order because of flooding. #abflood\""
      ],
      "metadata": {
        "id": "G9WVh3bf2dDD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(template=template_string)\n",
        "\n",
        "messages = prompt.format_messages(tweet=msg_3,\n",
        "                                format_instructions=format_instructions)\n",
        "\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTYSDM432oZs",
        "outputId": "7576cee2-7804-41ad-d879-8db68c863833"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='You are crisis response person that needs to understand the relevance of tweets. You help identify relevant information in a crisis.\\n\\nTake the tweet below delimited by triple backticks and use it to understand the sentiment, the crisis type and country it relates to.\\n\\ntweet: ```RT @CgyCA: UPDATE: Erlton, Victoria Park, Cliff Bungalow and Inglewood added to #yyc evacuation order because of flooding. #abflood```\\n\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"sentiment\": string  // This is the senitment of the tweet\\n\\t\"crisis_type\": string  // This is type of crisis (e.g. flooding, bushfire, typhoon)\\n\\t\"country\": string  // This is the country where the crisis is located\\n}\\n```\\n', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_llm(messages)\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG0hN3pn2s6S",
        "outputId": "eaccff8b-44fe-4fc4-dc70-02103c2fb490"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='```json\\n{\\n\\t\"sentiment\": \"neutral\",\\n\\t\"crisis_type\": \"flooding\",\\n\\t\"country\": \"Canada\"\\n}\\n```', additional_kwargs={}, example=False)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_as_dict = output_parser.parse(response.content)\n",
        "response_as_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Mes3UjF2xq2",
        "outputId": "6d7f3604-394c-4e02-e082-d00d82e9777c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentiment': 'neutral', 'crisis_type': 'flooding', 'country': 'Canada'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tweets from the 2012 Alberta floods are returning structure and predictable (maybe too predictable) dict formats. Let's try another crisis to understand if the model will pick up a different crisis in a different country."
      ],
      "metadata": {
        "id": "q1SU6mfY6zV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Message from the 2012 Colorado wildfires\n",
        "msg_4 = \"#Media Large wildfire in N. Colorado prompts evacuations: Crews are battling a fast-moving wildf... http://t.co/ju1BGTKH #Politics #News\""
      ],
      "metadata": {
        "id": "QW97F4u93PD1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(template=template_string)\n",
        "\n",
        "messages = prompt.format_messages(tweet=msg_4,\n",
        "                                format_instructions=format_instructions)\n",
        "\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbRs-za13Rwz",
        "outputId": "30b02179-6a31-4ba4-9f1f-e0145a08b371"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='You are crisis response person that needs to understand the relevance of tweets. You help identify relevant information in a crisis.\\n\\nTake the tweet below delimited by triple backticks and use it to understand the sentiment, the crisis type and country it relates to.\\n\\ntweet: ```#Media Large wildfire in N. Colorado prompts evacuations: Crews are battling a fast-moving wildf... http://t.co/ju1BGTKH #Politics #News```\\n\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"sentiment\": string  // This is the senitment of the tweet\\n\\t\"crisis_type\": string  // This is type of crisis (e.g. flooding, bushfire, typhoon)\\n\\t\"country\": string  // This is the country where the crisis is located\\n}\\n```\\n', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_llm(messages)\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSNyzV2I3Ufq",
        "outputId": "0016cb43-8840-4ad7-d611-966742a9aa19"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='```json\\n{\\n\\t\"sentiment\": \"neutral\",\\n\\t\"crisis_type\": \"wildfire\",\\n\\t\"country\": \"United States\"\\n}\\n```', additional_kwargs={}, example=False)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_as_dict = output_parser.parse(response.content)\n",
        "response_as_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb4KvPnG3YNq",
        "outputId": "20a9ead8-7b41-4f40-f9d8-e9305f44cf64"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentiment': 'neutral', 'crisis_type': 'wildfire', 'country': 'United States'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output looks useful and the country and crisis type of changed to align with the new information."
      ],
      "metadata": {
        "id": "hiwJfvJs7UQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Another message from the 2012 Colorado wildfires\n",
        "# This tweet is intersting as it mentions \"Belgium\". Will the model indetify the US as the country?\n",
        "msg_5 = \"RT @TheUmno: MT @KellyNehls: #photo Unedited photo from New Belgium Brewery #highparkfire #fortcollins #loc New Belgium Brewery # http:/ ...\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template=template_string)\n",
        "\n",
        "messages = prompt.format_messages(tweet=msg_5,\n",
        "                                format_instructions=format_instructions)\n",
        "\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaKHYVzg3htU",
        "outputId": "7011ccf2-c5dd-4999-f2cb-998f818ad345"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='You are crisis response person that needs to understand the relevance of tweets. You help identify relevant information in a crisis.\\n\\nTake the tweet below delimited by triple backticks and use it to understand the sentiment, the crisis type and country it relates to.\\n\\ntweet: ```RT @TheUmno: MT @KellyNehls: #photo Unedited photo from New Belgium Brewery #highparkfire #fortcollins #loc New Belgium Brewery # http:/ ...```\\n\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"sentiment\": string  // This is the senitment of the tweet\\n\\t\"crisis_type\": string  // This is type of crisis (e.g. flooding, bushfire, typhoon)\\n\\t\"country\": string  // This is the country where the crisis is located\\n}\\n```\\n', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_llm(messages)\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y7MhJBm3nFe",
        "outputId": "5c25aed4-db90-4608-c77d-d44d50d42c15"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='```json\\n{\\n\\t\"sentiment\": \"neutral\",\\n\\t\"crisis_type\": \"wildfire\",\\n\\t\"country\": \"United States\"\\n}\\n```', additional_kwargs={}, example=False)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_as_dict = output_parser.parse(response.content)\n",
        "response_as_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmYyHO0l3qvT",
        "outputId": "2c5a9efb-97dd-4c9a-ba51-50f56b2a4166"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentiment': 'neutral', 'crisis_type': 'wildfire', 'country': 'United States'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Country has been predicted correctly.\n",
        "\n",
        "## Results\n",
        "The method seems to produce predictable results that looks to be correct.\n",
        "\n",
        "## Next steps\n",
        "- Can Falcon 7B/Llama be used with the structuredoutputparser? If so, will it work as well?\n",
        "\n",
        "- Can this process be scaled?\n",
        "\n",
        "- Can it predict informativeness?\n",
        "\n",
        "## Questions/Thoughts\n",
        "Have these tweets been fed into the model during the training process? If so, is the model just regurgitating what it already knows? Would it be as effective on an unseen dataset?"
      ],
      "metadata": {
        "id": "FhaxL_mu7fsQ"
      }
    }
  ]
}